# SLMEF: Shortcut Learning Mitigation in Efficient Fine-tuning

![System Architecture](Images/System-Architechture.png)

##  AperÃ§u

SLMEF est un projet de recherche visant Ã  attÃ©nuer l'apprentissage par raccourci (shortcut learning) dans les grands modÃ¨les de langage (LLMs) tout en maintenant une efficacitÃ© computationnelle optimale. Ce projet combine des techniques de fine-tuning efficace des paramÃ¨tres avec des approches neuro-symboliques pour amÃ©liorer la robustesse des modÃ¨les dans des environnements Ã  ressources limitÃ©es.

##  FonctionnalitÃ©s

- IntÃ©gration de contraintes logiques neuro-symboliques
- Techniques de fine-tuning efficace (PEFT, LoRA)
- Ã‰valuation robuste sur des benchmarks adversariaux
- Optimisation pour matÃ©riel limitÃ©
- MÃ©triques complÃ¨tes d'Ã©valuation

## ğŸ›  Installation

1. Cloner le dÃ©pÃ´t :
```bash
git clone https://github.com/Codeur16/SLMEF-Shortcut-Learning-Mitigation-in-Efficient-Finetuning.git
cd SLMEF-Shortcut-Learning-Mitigation-in-Efficient-Finetuning
```

2. CrÃ©er et activer l'environnement virtuel :
```bash
python -m venv .venv
source .venv/bin/activate  # Sur Linux/Mac
# ou
.venv\Scripts\activate     # Sur Windows
```

3. Installer les dÃ©pendances :
```bash
pip install -r requirements.txt
```

## ğŸ— Structure du Projet

```
SLMEF-Shortcut-Learning-Mitigation-in-Efficient-Finetuning/
â”‚
â”œâ”€â”€ configs/           # Fichiers de configuration
â”œâ”€â”€ data/              # DonnÃ©es brutes
â”‚   â”œâ”€â”€ raw/           
â”‚   â””â”€â”€ processed/     
â”‚
â”œâ”€â”€ notebooks/         # Notebooks d'analyse et d'expÃ©rimentation
â”œâ”€â”€ outputs/           # Sorties des modÃ¨les et rÃ©sultats
â”‚   â”œâ”€â”€ models/        
â”‚   â””â”€â”€ predictions/   
â”‚
â”œâ”€â”€ src/               # Code source
â”‚   â”œâ”€â”€ detection/     # DÃ©tection des biais et raccourcis
â”‚   â”œâ”€â”€ symbolic/      # IntÃ©gration des contraintes symboliques
â”‚   â”œâ”€â”€ finetuning/    # ImplÃ©mentation des techniques de fine-tuning
â”‚   â”œâ”€â”€ evaluation/    # MÃ©triques et Ã©valuations
â”‚   â””â”€â”€ utils/         # Utilitaires
â”‚
â””â”€â”€ tests/             # Tests unitaires et d'intÃ©gration
```

## ğŸ§ª ExpÃ©rimentations

### Environnement

- **MatÃ©riel** :
  - Cloud : 2Ã— NVIDIA Tesla T4 (16GB), 2Ã— Intel Xeon 2.2GHz, 13GB RAM
  - Local : Intel Core i5, 16GB RAM, Intel UHD Graphics

- **Stack logicielle** :
  - Python 3.8+
  - PyTorch 2.5
  - Hugging Face Transformers v4.53.3
  - PEFT et LoRA

### Jeux de donnÃ©es

- **EntraÃ®nement** : MultiNLI
- **Ã‰valuation** : HANS, MNLI-hard (benchmarks adversariaux)
- **MÃ©triques** :
  - PrÃ©cision
  - Robustesse aux raccourcis
  - Temps d'entraÃ®nement
  - Nombre de paramÃ¨tres entraÃ®nables

##  Lancement

1. PrÃ©parer les donnÃ©es :
```bash
python -m src.data_preparation.prepare_data --config configs/data_config.yaml
```

2. Lancer l'entraÃ®nement :
```bash
python -m src.train --config configs/train_config.yaml
```

3. Ã‰valuer le modÃ¨le :
```bash
python -m src.evaluate --model_path outputs/models/best_model --test_data data/processed/test.jsonl
```

##  Visualisation des RÃ©sultats

Les rÃ©sultats sont sauvegardÃ©s dans le dossier `outputs/` :
- `outputs/logs/` : Journaux d'entraÃ®nement
- `outputs/checkpoints/` : Points de contrÃ´le des modÃ¨les
- `outputs/figures/` : Graphiques et visualisations

Pour visualiser les rÃ©sultats :
```bash
tensorboard --logdir=outputs/logs/
```

##  Contribution

Les contributions sont les bienvenues ! Pour contribuer :
1. Forkez le projet
2. CrÃ©ez une branche (`git checkout -b feature/AmazingFeature`)
3. Committez vos changements (`git commit -m 'Add some AmazingFeature'`)
4. Poussez vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrez une Pull Request

##  Licence

DistribuÃ© sous licence MIT. Voir `LICENSE` pour plus d'informations.

##  Contact

[Votre Nom] - [votre.email@example.com]

Lien du projet : [https://github.com/Codeur16/SLMEF-Shortcut-Learning-Mitigation-in-Efficient-Finetuning](https://github.com/Codeur16/SLMEF-Shortcut-Learning-Mitigation-in-Efficient-Finetuning)
â”œâ”€â”€ models/
â”œâ”€â”€ results/
â””â”€â”€ README.md
```
## Contacts
  * charlesnjiosseu@gmail.com
  * author-2@gmail.com
